Martin Escardo, Paulo Oliva, March - April 2023

This file is mostly for efficiency. See the tests with tic-tac-toe at
the end of this file with the various possibilities offered here.

We incorporate alpha-beta pruning to our previous work on finite
history-dependent games using the selection and continuous monads (in
the module GamesExperimental.FiniteHistoryDependent). But we do much more than
just that.

We define a minimax game (R , Xt, q , œït) to be a two-player game with
alternating quantifiers min and max (or max and min).

Part 0 (module minimax). In order to make the calculation of the
optimal outcome more efficient, we assume that the types of moves in
the game tree Xt are listed. Moreover, we add alpha-beta pruned
selection functions (indicated by the symbol "‚Ä†").

Part 1. We transform such a minimax game G into a game G' so that we
can read off optimal *plays* of G from optimal *outcomes* of G'. This
requires the construction of a new R' and new quantifiers max' and
min', and a proof that optimal outcomes of G' give optimal plays of G.

Part 2. We then add Œ±-Œ≤-pruning to G', to get a game G‚ãÜ, by further
modifying min' and max' to get min‚ãÜ and max‚ãÜ, but keeping R' the
same. This requires a proof that G' and G‚ãÜ have the same optimal
outcome. Of course, the Œ±-Œ≤-pruning is done for the sake of
efficiency. By combining this with Part 1, we obtain an efficient way
to play the original game G optimally, with a proof of
correctness. (But we don't prove efficiency theorems.)

\begin{code}

{-# OPTIONS --safe --without-K --no-exact-split --no-level-universe #-}

open import MLTT.Spartan hiding (J)

\end{code}

Part 0.

We now define standard minimax games.

\begin{code}

module GamesExperimental.alpha-beta-examples where

open import GamesExperimental.J
open import GamesExperimental.K
open import MLTT.Athenian
open import MLTT.Fin
open import Naturals.Order
open import UF.FunExt

\end{code}

Example from Wikipedia:
https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning

\begin{code}

module example-from-wikipedia where

 open import GamesExperimental.alpha-beta {ùì§‚ÇÄ} {ùì§‚ÇÄ} ‚Ñï _<‚Ñï_ <-decidable public

 wikipedia-tree : ùëª
 wikipedia-tree =
  Fin 3 ‚à∑
   Œª _ ‚Üí Fin 2 ‚à∑
          Œª _ ‚Üí Fin 2 ‚à∑
                 Œª _ ‚Üí Fin 3 ‚à∑
                        Œª _ ‚Üí []


 wikipedia-tree-is-listed‚Å∫ : structure listed‚Å∫ wikipedia-tree
 wikipedia-tree-is-listed‚Å∫ =
  Fin-listed‚Å∫ 2 ,
   Œª _ ‚Üí Fin-listed‚Å∫ 1 ,
          Œª _ ‚Üí Fin-listed‚Å∫ 1 ,
                 Œª _ ‚Üí Fin-listed‚Å∫ 2 ,
                        Œª _ ‚Üí ‚ü®‚ü©

 wikipedia-q : Path wikipedia-tree ‚Üí ‚Ñï
 wikipedia-q (ùüé , ùüé , ùüé , ùüé , ‚ü®‚ü©) = 5
 wikipedia-q (ùüé , ùüé , ùüé , _ , ‚ü®‚ü©) = 6
 wikipedia-q (ùüé , ùüé , ùüè , ùüé , ‚ü®‚ü©) = 7
 wikipedia-q (ùüé , ùüé , ùüè , ùüè , ‚ü®‚ü©) = 4
 wikipedia-q (ùüé , ùüé , ùüè , ùüê , ‚ü®‚ü©) = 5
 wikipedia-q (ùüé , ùüè , _ , _ , ‚ü®‚ü©) = 3
 wikipedia-q (ùüè , ùüé , ùüé , _ , ‚ü®‚ü©) = 6
 wikipedia-q (ùüè , ùüé , ùüè , ùüé , ‚ü®‚ü©) = 6
 wikipedia-q (ùüè , ùüé , ùüè , _ , ‚ü®‚ü©) = 9
 wikipedia-q (ùüè , ùüè , _ , _ , ‚ü®‚ü©) = 7
 wikipedia-q (ùüê , ùüé , _ , _ , ‚ü®‚ü©) = 5
 wikipedia-q (ùüê , _ , _ , _ , ‚ü®‚ü©) = 9

 module _ where

  open import Naturals.Order
  open minimax

  wikipedia-G : Game ‚Ñï
  wikipedia-G = G wikipedia-tree wikipedia-tree-is-listed‚Å∫ wikipedia-q

  wikipedia-optimal-play : Path wikipedia-tree
  wikipedia-optimal-play = optimal-play wikipedia-tree wikipedia-tree-is-listed‚Å∫ wikipedia-q

 wikipedia-optimal-outcome : ‚Ñï
 wikipedia-optimal-outcome = optimal-outcome ‚Ñï wikipedia-G

 wikipedia-optimal-outcomeÔºù : wikipedia-optimal-outcome Ôºù 6
 wikipedia-optimal-outcomeÔºù = refl

 {- Comment out because it is slow:

 wikipedia-optimal-playÔºù : wikipedia-optimal-play Ôºù (ùüè , ùüé , ùüé , ùüé , ‚ü®‚ü©)
 wikipedia-optimal-playÔºù = refl
 -}

\end{code}

Example from Wikipedia again.

\begin{code}

module example-from-wikipedia' where

 open example-from-wikipedia

 wikipedia-G' : Game (‚Ñï √ó Path wikipedia-tree)
 wikipedia-G' = G' wikipedia-tree wikipedia-tree-is-listed‚Å∫ wikipedia-q
  where
   open minimax'

 wikipedia-optimal-outcome' : ‚Ñï √ó Path wikipedia-tree
 wikipedia-optimal-outcome' = optimal-outcome (‚Ñï √ó Path wikipedia-tree) wikipedia-G'

 wikipedia-optimal-outcomeÔºù' : wikipedia-optimal-outcome' Ôºù (6 , ùüè , ùüé , ùüé , ùüé , ‚ü®‚ü©)
 wikipedia-optimal-outcomeÔºù' = refl

\end{code}

module example-from-wikipedia' where

 open import GamesExperimental.alpha-beta {?} {?} ? ? ?

 wikipedia-G‚ãÜ : Game (‚Ñï √ó ‚Ñï ‚Üí ‚Ñï √ó Path wikipedia-tree)
 wikipedia-G‚ãÜ = G‚ãÜ
  where
   open minimax‚ãÜ
         ‚Ñï
         0 10
         _<‚Ñï_
         <-decidable
         wikipedia-tree
         wikipedia-tree-is-listed‚Å∫
         wikipedia-q

 wikipedia-optimal-outcome‚ãÜ : ‚Ñï √ó ‚Ñï ‚Üí ‚Ñï √ó Path wikipedia-tree
 wikipedia-optimal-outcome‚ãÜ = optimal-outcome (‚Ñï √ó ‚Ñï ‚Üí ‚Ñï √ó Path wikipedia-tree) wikipedia-G‚ãÜ

 wikipedia-optimal-outcomeÔºù‚ãÜ : wikipedia-optimal-outcome‚ãÜ (0 , 10)
                             Ôºù (6 , ùüè , ùüé , ùüé , ùüé , ‚ü®‚ü©)
 wikipedia-optimal-outcomeÔºù‚ãÜ = refl

\end{code}

Two versions of tic-tac-toe.

\begin{code}

module tic-tac-toe where

 open import GamesExperimental.alpha-beta {ùì§‚ÇÄ} {ùì§‚ÇÄ} ‚Ñï _<‚Ñï_ <-decidable

 module _ {X : ùì§‚ÇÄ Ãá }
        where

  open list-util

  perm-tree : {n : ‚Ñï} ‚Üí Vector' X n ‚Üí ùëª
  perm-tree {0}        ([] , _) = []
  perm-tree {succ n} v@(xs , _) = type-from-list xs
                                ‚à∑ Œª (_ , m) ‚Üí perm-tree {n} (delete v m)

  perm-tree-is-listed‚Å∫ : {n : ‚Ñï}
                           (v : Vector' X n)
                         ‚Üí structure listed‚Å∫ (perm-tree {n} v)
  perm-tree-is-listed‚Å∫ {0}      ([]         , _) = ‚ü®‚ü©
  perm-tree-is-listed‚Å∫ {succ n} (xs@(y ‚à∑ _) , p) = ((y , in-head) , type-from-list-is-listed xs)
                                                   :: Œª (_ , m) ‚Üí perm-tree-is-listed‚Å∫ {n}
                                                                   (delete (xs , p) m)

  remove-proofs : (n : ‚Ñï) (v : Vector' X n)
                ‚Üí Path (perm-tree v)
                ‚Üí List X
  remove-proofs 0 _ _    = []
  remove-proofs (succ n) moves ((m , m-is-in-moves) :: ms)  =
   m ‚à∑ remove-proofs n (delete moves m-is-in-moves) ms

 open list-util {ùì§‚ÇÄ} {‚Ñï}

 module version‚ÇÅ where

  Move = ‚Ñï -- We use 0 , ‚ãØ , 8 only

  all-moves : Vector' Move 9
  all-moves = (0 ‚à∑ 1 ‚à∑ 2 ‚à∑ 3 ‚à∑ 4 ‚à∑ 5 ‚à∑ 6 ‚à∑ 7 ‚à∑ 8 ‚à∑ []) , refl

  TTT-tree : ùëª
  TTT-tree = perm-tree all-moves

  TTT-tree-is-listed‚Å∫ : structure listed‚Å∫ TTT-tree
  TTT-tree-is-listed‚Å∫ = perm-tree-is-listed‚Å∫ all-moves

  R      = ‚Ñï -- We use 0 (minimizer player wins) , 1 (draw) , 2 (maximizer player wins)
  Board  = List Move √ó List Move -- Moves of maximizer, respectively minimizer, player so far

  initial-board : Board
  initial-board = [] , []

  wins : List Move ‚Üí Bool
  wins =
   some-contained ((0  ‚à∑ 1  ‚à∑ 2 ‚à∑ [])
                 ‚à∑ (3  ‚à∑ 4  ‚à∑ 5 ‚à∑ [])
                 ‚à∑ (6  ‚à∑ 7  ‚à∑ 8 ‚à∑ [])
                 ‚à∑ (0  ‚à∑ 3  ‚à∑ 6 ‚à∑ [])
                 ‚à∑ (1  ‚à∑ 4  ‚à∑ 7 ‚à∑ [])
                 ‚à∑ (2  ‚à∑ 5  ‚à∑ 8 ‚à∑ [])
                 ‚à∑ (0  ‚à∑ 4  ‚à∑ 8 ‚à∑ [])
                 ‚à∑ (2  ‚à∑ 4  ‚à∑ 6 ‚à∑ [])
                 ‚à∑ [])

  value : Board ‚Üí R
  value (x , o) = if wins x then 2 else if wins o then 0 else 1

  data Player : ùì§‚ÇÄ  Ãá  where
   X O : Player

  maximizing-player : Player
  maximizing-player = X

  TTT-q : Path TTT-tree ‚Üí R
  TTT-q ms = value (g ms)
   where
    h : (n : ‚Ñï) (moves : Vector' Move n) ‚Üí Path (perm-tree moves) ‚Üí Player ‚Üí Board ‚Üí Board
    h 0 _ _ _  board = board
    h (succ n) moves ((m , m-is-in-moves) :: ms) X (x , o) =
      if wins o
      then (x , o)
      else h n (delete moves m-is-in-moves) ms O (insert m x , o)
    h (succ n) moves ((m , m-is-in-moves) :: ms) O (x , o) =
      if wins x
      then (x , o)
      else h n (delete moves m-is-in-moves) ms X (x , insert m o)

    g : Path TTT-tree ‚Üí Board
    g ms = h 9 all-moves ms maximizing-player initial-board

  TTT-G : Game R
  TTT-G = G TTT-tree TTT-tree-is-listed‚Å∫ TTT-q
   where
    open minimax

  TTT-optimal-outcome : R
  TTT-optimal-outcome = optimal-outcome R TTT-G

  TTT-G' : Game (R √ó Path TTT-tree)
  TTT-G' = G' TTT-tree TTT-tree-is-listed‚Å∫ TTT-q
   where
    open minimax'

  TTT-optimal-outcome' : R √ó Path TTT-tree
  TTT-optimal-outcome' = optimal-outcome (R √ó Path TTT-tree) TTT-G'

  TTT-G‚ãÜ : Game (R √ó R ‚Üí R √ó Path TTT-tree)
  TTT-G‚ãÜ = G‚ãÜ TTT-tree TTT-tree-is-listed‚Å∫ TTT-q 0 2
   where
    open minimax‚ãÜ

  TTT-optimal-outcome‚ãÜ : R √ó Path TTT-tree
  TTT-optimal-outcome‚ãÜ = optimal-outcome (R √ó R ‚Üí R √ó Path TTT-tree) TTT-G‚ãÜ (0 , 2)


  TTT-optimal-play : Path TTT-tree
  TTT-optimal-play = optimal-play TTT-tree TTT-tree-is-listed‚Å∫ TTT-q
   where
    open minimax

  TTT-optimal-play‚Ä† : Fun-Ext ‚Üí Path TTT-tree
  TTT-optimal-play‚Ä† fe = optimal-play‚Ä† TTT-tree TTT-tree-is-listed‚Å∫ TTT-q fe 0 2
   where
    open minimax

 module version‚ÇÇ  where

  Move = ‚Ñï √ó ‚Ñï

  all-moves : Vector' Move 9
  all-moves = ((0 , 0) ‚à∑ (0 , 1) ‚à∑ (0 , 2)
             ‚à∑ (1 , 0) ‚à∑ (1 , 1) ‚à∑ (1 , 2)
             ‚à∑ (2 , 0) ‚à∑ (2 , 1) ‚à∑ (2 , 2) ‚à∑ []) ,
            refl

  TTT-tree : ùëª
  TTT-tree = perm-tree all-moves

  TTT-tree-is-listed‚Å∫ : structure listed‚Å∫ TTT-tree
  TTT-tree-is-listed‚Å∫ = perm-tree-is-listed‚Å∫ all-moves

  data Player : ùì§‚ÇÄ  Ãá  where
   X O : Player

  opponent : Player ‚Üí Player
  opponent X = O
  opponent O = X

  maximizing-player : Player
  maximizing-player = X

  R      = ‚Ñï -- We use 0 (minimizer player wins) , 1 (draw) , 2 (maximizer player wins)
  Grid   = Move
  Matrix = Grid ‚Üí Maybe Player
  Board  = Player √ó Matrix

  initial-board : Board
  initial-board = O , (Œª _ ‚Üí Nothing)

  wins : Board ‚Üí Bool
  wins (p , A) = line || col || diag
   where
    _is_ : Maybe Player ‚Üí Player ‚Üí Bool
    Nothing is _ = false
    Just X  is X = true
    Just O  is X = false
    Just X  is O = false
    Just O  is O = true

    infix 30 _is_

    l‚ÇÄ = A (0 , 0) is p && A (0 , 1) is p && A (0 , 2) is p
    l‚ÇÅ = A (1 , 0) is p && A (1 , 1) is p && A (1 , 2) is p
    l‚ÇÇ = A (2 , 0) is p && A (2 , 1) is p && A (2 , 2) is p

    c‚ÇÄ = A (0 , 0) is p && A (1 , 0) is p && A (2 , 0) is p
    c‚ÇÅ = A (0 , 1) is p && A (1 , 1) is p && A (2 , 1) is p
    c‚ÇÇ = A (0 , 2) is p && A (1 , 2) is p && A (2 , 2) is p

    d‚ÇÄ = A (0 , 0) is p && A (1 , 1) is p && A (2 , 2) is p
    d‚ÇÅ = A (0 , 2) is p && A (1 , 1) is p && A (2 , 0) is p

    line = l‚ÇÄ || l‚ÇÅ || l‚ÇÇ
    col  = c‚ÇÄ || c‚ÇÅ || c‚ÇÇ
    diag = d‚ÇÄ || d‚ÇÅ

  value : Board ‚Üí R
  value b@(X , _) = if wins b then 2 else 1
  value b@(O , _) = if wins b then 0 else 1

  update : Move ‚Üí Board ‚Üí Board
  update (i‚ÇÄ , j‚ÇÄ) (player , A) = (player' , A')
   where
    player' = opponent player

    A' : Matrix
    A' (i , j) = if (i == i‚ÇÄ) && (j == j‚ÇÄ) then Just player' else A (i , j)

  TTT-q : Path TTT-tree ‚Üí R
  TTT-q ms = value (g ms)
   where
    h : (n : ‚Ñï) (moves : Vector' Move n) ‚Üí Path (perm-tree moves) ‚Üí Board ‚Üí Board
    h 0 _ _  board = board
    h (succ n) moves ((m , m-is-in-moves) :: ms) board =
      if wins board
      then board
      else h n (delete moves m-is-in-moves) ms (update m board)

    g : Path TTT-tree ‚Üí Board
    g ms = h 9 all-moves ms initial-board

  TTT-G : Game R
  TTT-G = G TTT-tree TTT-tree-is-listed‚Å∫ TTT-q
   where
    open minimax

  TTT-optimal-outcome : R
  TTT-optimal-outcome = optimal-outcome R TTT-G

  TTT-G' : Game (R √ó Path TTT-tree)
  TTT-G' = G' TTT-tree TTT-tree-is-listed‚Å∫ TTT-q
   where
    open minimax'

  TTT-optimal-outcome' : R √ó Path TTT-tree
  TTT-optimal-outcome' = optimal-outcome (R √ó Path TTT-tree) TTT-G'

  TTT-G‚ãÜ : Game (R √ó R ‚Üí R √ó Path TTT-tree)
  TTT-G‚ãÜ = G‚ãÜ TTT-tree TTT-tree-is-listed‚Å∫ TTT-q 0 2
   where
    open minimax‚ãÜ

  TTT-optimal-outcome‚ãÜ : R √ó Path TTT-tree
  TTT-optimal-outcome‚ãÜ = optimal-outcome (R √ó R ‚Üí R √ó Path TTT-tree) TTT-G‚ãÜ (0 , 2)

\end{code}

Slow. 28 minutes in a MacBook Air M1
 TTT-optimal-outcomeÔºù‚ãÜ : TTT-optimal-outcome‚ãÜ
                       Ôºù (1 , ((0 :: in-head)
                            :: ((4 :: in-tail (in-tail (in-tail in-head)))
                            :: ((1 :: in-head)
                            :: ((2 :: in-head)
                            :: ((6 :: in-tail (in-tail in-head))
                            :: ((3 :: in-head)
                            :: ((5 :: in-head)
                            :: ((7 :: in-head)
                            :: ((8 :: in-head)
                            :: ‚ü®‚ü©))))))))))
 TTT-optimal-outcomeÔºù‚ãÜ = refl

This computes the optimal outcome using the standard minimax
algorithm with quantifiers:

\begin{code}

test : ‚Ñï -- 22.7 seconds with `agda --compile` on a Mac M2
test = TTT-optimal-outcome
 where
  open tic-tac-toe
  open version‚ÇÅ

\end{code}

This is like test above, but using a different implementation of
the tic-tac-toe board:

\begin{code}

-test : ‚Ñï -- 22.6 seconds with `agda --compile` on a Mac M2
-test = TTT-optimal-outcome
 where
  open tic-tac-toe
  open version‚ÇÇ


\end{code}

This tries to compute an optimal play using selection functions
without any optimization:

\begin{code}

testo : List ‚Ñï -- It didn't finish in 7 hours  with `agda --compile` on a Mac M2
testo = remove-proofs _ all-moves TTT-optimal-play
 where
  open tic-tac-toe
  open version‚ÇÅ

\end{code}

This computes an optimal play using monadic selection functions,
with the reader monad, to implement alpha-beta prunning, which is a
new technique introduced in this file:

\begin{code}

test‚Ä† : Fun-Ext ‚Üí List ‚Ñï -- 15 seconds with `agda --compile` on a Mac M2
test‚Ä† fe = remove-proofs _ all-moves (TTT-optimal-play‚Ä† fe)
 where
  open tic-tac-toe
  open version‚ÇÅ

\end{code}

This computes an optimal play using quantifiers, which is a new
technique introduced in this file:

\begin{code}

test' : List ‚Ñï -- 22.7 seconds with `agda --compile` on a Mac M2
test' = remove-proofs _ all-moves (pr‚ÇÇ TTT-optimal-outcome')
 where
  open tic-tac-toe
  open version‚ÇÅ

\end{code}

This is like test' above, but uses a different implementation of the
tic-tac-toe board:

\begin{code}

-test' : List (‚Ñï √ó ‚Ñï) -- 27.7 seconds with `agda --compile` on a Mac M2
-test' = remove-proofs _ all-moves (pr‚ÇÇ TTT-optimal-outcome')
 where
  open tic-tac-toe
  open version‚ÇÇ

\end{code}

This computes again an optimal play using monadic quantifiers, with
the reader monad, rather than selection functions, to implement
alpha-beta prunning, which is also a new thing in this file:

\begin{code}

test‚ãÜ : List ‚Ñï -- 2.8 seconds with `agda --compile` on a Mac M2
test‚ãÜ = remove-proofs _ all-moves (pr‚ÇÇ TTT-optimal-outcome‚ãÜ)
 where
  open tic-tac-toe
  open version‚ÇÅ

\end{code}

This is like test‚ãÜ above, but uses a different implementation of
the tic-tac-toe board:

\begin{code}

-test‚ãÜ : List (‚Ñï √ó ‚Ñï) -- 3.3 seconds with `agda --compile` on a Mac M2
-test‚ãÜ = remove-proofs _ all-moves (pr‚ÇÇ TTT-optimal-outcome‚ãÜ)
 where
  open tic-tac-toe
  open version‚ÇÇ

\end{code}

So the alpha-beta prunned version is 8 times faster.

NB. The strictness option for compilation quadruples the run time.

TODO:

 * Formulate the correctness of G' and G‚ãÜ.
   (Actually done above in commented-out Agda code.)

 * Prove it!
